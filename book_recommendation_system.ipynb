{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book Recommender System using GoodReads Ratings\n",
    "\n",
    "This Jupyter notebook implements a book recommender system using ratings data from Goodreads, a popular online platform for book enthusiasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import data\n",
    "\n",
    "from IPython.display import HTML as html_print\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurable parameters, change as needed\n",
    "\n",
    "# set to true if loading existing model file, false if training a new model\n",
    "skip_training = True\n",
    "explicit = False\n",
    "data_dir = 'data'\n",
    "model_save_path = 'models/goodreads_recsys.pth'\n",
    "\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dirs if not existing\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('logs', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device type: cpu\n"
     ]
    }
   ],
   "source": [
    "# additional settings, automatically selects cuda if available\n",
    "if skip_training:\n",
    "    device_type = 'cpu'\n",
    "elif torch.cuda.is_available():\n",
    "    device_type = 'cuda:0'\n",
    "else:\n",
    "    device_type = 'cpu'\n",
    "\n",
    "# set manually if needed e.g. device_type = 'cpu'\n",
    "print(\"Using device type:\", device_type)\n",
    "device = torch.device(device_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: train, User count: 6769, Book count: 92034, Ratings count: 966946\n",
      "Dataset: test, User count: 6376, Book count: 79887, Ratings count: 288004\n"
     ]
    }
   ],
   "source": [
    "trainset = data.GoodReadsRatingsDataset(root=data_dir, mode='train', explicit=explicit)\n",
    "testset = data.GoodReadsRatingsDataset(root=data_dir, mode='test', explicit=explicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1024, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommenderSystem(nn.Module):\n",
    "    def __init__(self, n_users, n_items):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          n_users: Number of users.\n",
    "          n_items: Number of items.\n",
    "        \"\"\"\n",
    "        super(RecommenderSystem, self).__init__()\n",
    "\n",
    "        self.user_em = nn.Embedding(n_users, 20)\n",
    "        self.item_em = nn.Embedding(n_items, 100)\n",
    "        self.drop0 = nn.Dropout(0.02)\n",
    "        \n",
    "        self.fc1 = nn.Linear(120, 100)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.drop1 = nn.Dropout(0.02)\n",
    "        \n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.drop2 = nn.Dropout(0.02)\n",
    "        \n",
    "        self.fc3 = nn.Linear(10, 1)\n",
    "        \n",
    "    def forward(self, user_ids, item_ids):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          user_ids of shape (batch_size): User ids (starting from 0).\n",
    "          item_ids of shape (batch_size): Item ids (starting from 0).\n",
    "        \n",
    "        Returns:\n",
    "          outputs of shape (batch_size): Predictions of ratings.\n",
    "        \"\"\"\n",
    "        x = torch.cat([self.user_em(user_ids), self.item_em(item_ids)], dim=1)\n",
    "        x = self.drop0(x)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.drop1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.drop2(x)\n",
    "\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        # min_rating, max_rating = (0.5, 5.5)\n",
    "        # x = x*(max_rating - min_rating) + min_rating\n",
    "        x = x.view(-1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecommenderSystem(\n",
       "  (user_em): Embedding(6769, 20)\n",
       "  (item_em): Embedding(92034, 100)\n",
       "  (drop0): Dropout(p=0.02, inplace=False)\n",
       "  (fc1): Linear(in_features=120, out_features=100, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (drop1): Dropout(p=0.02, inplace=False)\n",
       "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (drop2): Dropout(p=0.02, inplace=False)\n",
       "  (fc3): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RecommenderSystem(trainset.n_users, trainset.n_items)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes the loss:\n",
    "def compute_loss(model, testloader):\n",
    "    model.eval()\n",
    "    cost = nn.MSELoss()\n",
    "    total_loss = 0\n",
    "    total_data = 0\n",
    "    prediction_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for user_ids, item_ids, labels in testloader:\n",
    "            user_ids, item_ids, labels = user_ids.to(device), item_ids.to(device), labels.to(device)\n",
    "            predictions = model(user_ids, item_ids)\n",
    "            prediction_list.append(predictions.cpu())\n",
    "\n",
    "            loss = cost(predictions, labels)\n",
    "            total_loss += (loss.item() * labels.size(0))\n",
    "            total_data += labels.size(0)\n",
    "\n",
    "    loss = total_loss / total_data\n",
    "    return torch.cat(prediction_list), loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "if not skip_training:\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "    cost = nn.MSELoss()\n",
    "    total_loss = 0\n",
    "    total_data = 0\n",
    "\n",
    "    # save historical losses and accs\n",
    "    hist_metrics = dict()\n",
    "    hist_metrics['epoch'] = []\n",
    "    hist_metrics['train_loss'] = []\n",
    "    hist_metrics['test_loss'] = []\n",
    "\n",
    "    epochs = 20\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for user_ids, item_ids, labels in trainloader:  \n",
    "            user_ids, item_ids, labels = user_ids.to(device), item_ids.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(user_ids, item_ids)\n",
    "\n",
    "            loss = cost(predictions, labels)\n",
    "            total_loss += (loss.item() * labels.size(0))\n",
    "            total_data += labels.size(0)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss = total_loss / total_data\n",
    "        _, test_loss = compute_loss(model, testloader)\n",
    "\n",
    "        hist_metrics['epoch'].append(epoch)\n",
    "        hist_metrics['train_loss'].append(train_loss)\n",
    "        hist_metrics['test_loss'].append(test_loss)\n",
    "\n",
    "        print('Epoch {}: Train error: {:.4f}, Test error: {:.4f}'.format(epoch, train_loss, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot and save historical train/test loss\n",
    "def plot_metrics(metrics, save_path='logs/goodreads_recsys_{}.{}'):\n",
    "    plt.plot(metrics['train_loss'])\n",
    "    plt.plot(metrics['test_loss'])\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig(save_path.format('loss', \"png\"))\n",
    "    plt.show()\n",
    "\n",
    "    with open(save_path.format(\"hist\", \"json\"), 'w') as f:\n",
    "        json.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained model\n",
    "if not skip_training:\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    plot_metrics(hist_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: models/goodreads_recsys.pth\n"
     ]
    }
   ],
   "source": [
    "if skip_training:\n",
    "    model = RecommenderSystem(trainset.n_users, trainset.n_items)\n",
    "    model.load_state_dict(torch.load(model_save_path, map_location=lambda storage, loc: storage))\n",
    "    print('Model loaded from: {}'.format(model_save_path))\n",
    "    model.to(device)\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.1816\n"
     ]
    }
   ],
   "source": [
    "predictions, loss = compute_loss(model, testloader)\n",
    "print('Test loss: {:.4f}'.format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_titles_df = pd.read_csv(os.path.join(data_dir, 'book_titles.csv'), header=0)\n",
    "book_titles_df.set_index('encoded_book_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 50% hit rate: 0.7215026617050171\n",
      "top 10 hit rate: 0.7813742160797119\n",
      "top 1 hit rate: 0.8574341535568237\n"
     ]
    }
   ],
   "source": [
    "next_user_i = 0\n",
    "top_half_hit = 0\n",
    "top10_hit = 0\n",
    "top01_hit = 0\n",
    "count = 0\n",
    "\n",
    "while next_user_i < len(testset):\n",
    "    user_id = testset[next_user_i][0]\n",
    "    last_user_i = next_user_i\n",
    "    while next_user_i < len(testset) and testset[next_user_i][0] == user_id:\n",
    "        next_user_i += 1\n",
    "    indices = range(last_user_i, next_user_i)\n",
    "\n",
    "    labels = testset[indices][2]\n",
    "    _, top_reco = torch.topk(predictions[indices], k=int(len(indices)/2))\n",
    "    top_half_hit += labels[top_reco].sum()/int(len(indices)/2)\n",
    "\n",
    "    _, top_reco = torch.topk(predictions[indices], k=min(int(len(indices)/2), 10))\n",
    "    top10_hit += labels[top_reco].sum()/min(int(len(indices)/2), 10)\n",
    "\n",
    "    _, top_reco = torch.topk(predictions[indices], k=1)\n",
    "    top01_hit += labels[top_reco].sum()\n",
    "\n",
    "    count += 1\n",
    "\n",
    "\n",
    "top_half_hit = top_half_hit / count\n",
    "print(\"top 50% hit rate:\", top_half_hit.item())\n",
    "top10_hit = top10_hit / count\n",
    "print(\"top 10 hit rate:\", top10_hit.item())\n",
    "top01_hit = top01_hit / count\n",
    "print(\"top 1 hit rate:\", top01_hit.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing (sample) books from user_enc_id=1117\n",
      "85.00% of the books have been correctly recommended\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "|   encoded_book_id |   book_id | title                                                                                                   | read?                                   | recommend?                              | correctly recommended?                  |\n",
       "|------------------:|----------:|:--------------------------------------------------------------------------------------------------------|:----------------------------------------|:----------------------------------------|:----------------------------------------|\n",
       "|              6406 |    256683 | City of Bones (The Mortal Instruments, #1)                                                              | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> |\n",
       "|               188 |      6969 | Emma                                                                                                    | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> |\n",
       "|             41724 |  11857408 | Fifty Shades Darker (Fifty Shades, #2)                                                                  | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> |\n",
       "|             38998 |  10818853 | Fifty Shades of Grey (Fifty Shades, #1)                                                                 | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> |\n",
       "|              9585 |    476494 | Heart of the Dragon (Atlantis, #1)                                                                      | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> |\n",
       "|              9585 |    476494 | Heart of the Dragon (Atlantis, #1)                                                                      | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> |\n",
       "|             22674 |   3475054 | Hex Appeal (Hex #2)                                                                                     | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> |\n",
       "|             26156 |   6376794 | Hex in High Heels (Hex, #4)                                                                             | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #ff0000\">no</span>  |\n",
       "|             26156 |   6376794 | Hex in High Heels (Hex, #4)                                                                             | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #ff0000\">no</span>  |\n",
       "|              4684 |    146744 | Jewel of Atlantis (Atlantis, #2)                                                                        | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> |\n",
       "|              4684 |    146744 | Jewel of Atlantis (Atlantis, #2)                                                                        | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> |\n",
       "|              1782 |     38548 | Love Bites (Argeneau #2)                                                                                | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> |\n",
       "|             27888 |   6668868 | Pride Mates (Shifters Unbound, #1)                                                                      | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> |\n",
       "|             32115 |   8112340 | Primal Bonds (Shifters Unbound, #2)                                                                     | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> |\n",
       "|             31114 |   7812659 | Safe Haven                                                                                              | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> |\n",
       "|             60093 |  17407748 | The Longest Ride                                                                                        | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> |\n",
       "|              3570 |     96131 | The Nymph King (Atlantis, #3)                                                                           | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> |\n",
       "|              3570 |     96131 | The Nymph King (Atlantis, #3)                                                                           | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> |\n",
       "|              9072 |    432522 | The Pleasure Slave (Imperia, #2)                                                                        | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #00ff00\">yes</span> |\n",
       "|              9945 |    501435 | Under Cover                                                                                             | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #ff0000\">no</span>  |\n",
       "|             24578 |   5999949 | Wicked by Any Other Name (Hex, #3)                                                                      | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #ff0000\">no</span>  |\n",
       "|             82701 |  23736027 | Alpha Contender Volume 1                                                                                | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #00ff00\">yes</span> |\n",
       "|             87812 |  25944381 | Cruel Crown (Red Queen, #0.1-#0.2)                                                                      | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #ff0000\">no</span>  |\n",
       "|             49240 |  13601567 | Gifted (Donovan Circus, #1)                                                                             | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #00ff00\">yes</span> |\n",
       "|             58609 |  17254498 | Gölge ve Kemik  (The Grisha, #1)                                                                        | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #00ff00\">yes</span> |\n",
       "|             22603 |   3430869 | Mister Mistress, Volume 2                                                                               | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #00ff00\">yes</span> |\n",
       "|             79219 |  22857416 | Off Campus (Bend or Break, #1)                                                                          | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #00ff00\">yes</span> |\n",
       "|             31895 |   8029972 | Our World (The Dresden Files Roleplaying Game, #2; The Dresden Files, #10.11)                           | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #00ff00\">yes</span> |\n",
       "|             20414 |   2409564 | Ravenous                                                                                                | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #00ff00\">yes</span> |\n",
       "|              9710 |    485933 | Record of Lodoss War: Chronicles of the Heroic Knight, Book Three (Chronicles of the Heroic Knight, #3) | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #00ff00\">yes</span> |\n",
       "|             24475 |   5971977 | Rough Stock                                                                                             | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #00ff00\">yes</span> |\n",
       "|             80975 |  23311422 | Shiver: 13 Sexy Tales of Humor and Horror                                                               | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #00ff00\">yes</span> |\n",
       "|             33131 |   8439097 | The Ambassador's Mission (Traitor Spy Trilogy, #1)                                                      | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #00ff00\">yes</span> |\n",
       "|             13781 |    851218 | The Supernaturalist                                                                                     | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #00ff00\">yes</span> |\n",
       "|             30341 |   7556058 | Tracking the Tempest (Jane True, #2)                                                                    | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #00ff00\">yes</span> | <span style=\"color: #ff0000\">no</span>  |\n",
       "|             85388 |  25192682 | Tragic Soul (Triple Threat, #0.75)                                                                      | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #00ff00\">yes</span> |\n",
       "|             79124 |  22846945 | Traitor's Blade (Greatcoats, #1)                                                                        | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #00ff00\">yes</span> |\n",
       "|             25048 |   6110386 | Virgin Mistress, Scandalous Love-Child                                                                  | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #00ff00\">yes</span> |\n",
       "|             83860 |  24578509 | War                                                                                                     | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #00ff00\">yes</span> |\n",
       "|             15668 |   1108017 | Where Angels Go (Angels Everywhere, #6)                                                                 | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #ff0000\">no</span>  | <span style=\"color: #00ff00\">yes</span> |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indices = testset.get_user_record()\n",
    "sampleset = torch.utils.data.Subset(testset, indices)\n",
    "sampleloader = torch.utils.data.DataLoader(sampleset, batch_size=len(indices), shuffle=False)\n",
    "\n",
    "if explicit:\n",
    "    max_range = 5.0\n",
    "else:\n",
    "    max_range = 1.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for user_ids, item_ids, labels in sampleloader:\n",
    "        print(\"Showing (sample) books from user_enc_id={}\".format(user_ids[0]))\n",
    "        user_ids, item_ids, labels = user_ids.to(device), item_ids.to(device), labels.to(device)\n",
    "        predictions = model(user_ids, item_ids)\n",
    "\n",
    "        tmp_df = book_titles_df.loc[item_ids.cpu()]\n",
    "        tmp_df['actual_ratings'] = labels.cpu() * max_range\n",
    "        tmp_df['predicted_ratings'] = predictions.cpu().round(decimals=2) * max_range\n",
    "        tmp_df['correct'] = (tmp_df['predicted_ratings'].round() == tmp_df['actual_ratings'])\n",
    "        \n",
    "        # display title of correct predictions as green\n",
    "        # tmp_df.loc[tmp_df['correct'], 'title'] = '<span style=\"color: #00ff00\">' + tmp_df.loc[tmp_df['correct'], 'title'] + '</span>'\n",
    "        # display title of correct predictions as red\n",
    "        # tmp_df.loc[~tmp_df['correct'], 'title'] = '<span style=\"color: #ff0000\">' + tmp_df.loc[~tmp_df['correct'], 'title'] + '</span>'\n",
    "        \n",
    "        tmp_df = tmp_df.sample(n=min(len(tmp_df.index), 40))\n",
    "        tmp_df.sort_values(by=['actual_ratings', 'title'], ascending=[False, True], inplace=True)\n",
    "\n",
    "        tmp_df['read?'] = '<span style=\"color: #ff0000\">no</span>'\n",
    "        tmp_df.loc[tmp_df['actual_ratings'] == 1, 'read?'] = '<span style=\"color: #00ff00\">yes</span>'\n",
    "        \n",
    "        tmp_df['recommend?'] = '<span style=\"color: #ff0000\">no</span>'\n",
    "        tmp_df.loc[tmp_df['predicted_ratings'] >= 0.5, 'recommend?'] = '<span style=\"color: #00ff00\">yes</span>'\n",
    "\n",
    "        tmp_df['correctly recommended?'] = '<span style=\"color: #ff0000\">no</span>'\n",
    "        tmp_df.loc[tmp_df['correct'] == 1, 'correctly recommended?'] = '<span style=\"color: #00ff00\">yes</span>'\n",
    "\n",
    "        print(\"{:.2f}% of the books have been correctly recommended\".format(tmp_df['correct'].sum() / len(tmp_df['correct']) * 100))\n",
    "        # display(tmp_df[['book_id', 'title', 'actual_ratings', 'predicted_ratings', 'correct', 'test']])\n",
    "        display(Markdown(tmp_df[['book_id', 'title', 'read?', 'recommend?', 'correctly recommended?']].to_markdown()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|   encoded_book_id | title                                                                       |   predicted_ratings |\n",
       "|------------------:|:----------------------------------------------------------------------------|--------------------:|\n",
       "|                 2 | Harry Potter and the Sorcerer's Stone (Harry Potter, #1)                    |                0.94 |\n",
       "|                 0 | Harry Potter and the Half-Blood Prince (Harry Potter, #6)                   |                0.93 |\n",
       "|                 4 | Harry Potter and the Goblet of Fire (Harry Potter, #4)                      |                0.93 |\n",
       "|               728 | Harry Potter and the Chamber of Secrets (Harry Potter, #2)                  |                0.93 |\n",
       "|              4516 | Harry Potter and the Deathly Hallows (Harry Potter, #7)                     |                0.93 |\n",
       "|                18 | The Fellowship of the Ring (The Lord of the Rings, #1)                      |                0.92 |\n",
       "|               438 | A Game of Thrones (A Song of Ice and Fire, #1)                              |                0.91 |\n",
       "|                57 | Pride and Prejudice                                                         |                0.91 |\n",
       "|              1165 | The Lightning Thief (Percy Jackson and the Olympians, #1)                   |                0.91 |\n",
       "|                 1 | Harry Potter and the Order of the Phoenix (Harry Potter, #5)                |                0.91 |\n",
       "|              5298 | The Name of the Wind (The Kingkiller Chronicle, #1)                         |                0.9  |\n",
       "|              3697 | The Lion, the Witch, and the Wardrobe (Chronicles of Narnia, #1)            |                0.9  |\n",
       "|               634 | The Two Towers (The Lord of the Rings, #2)                                  |                0.9  |\n",
       "|               843 | The Return of the King (The Lord of the Rings, #3)                          |                0.9  |\n",
       "|               160 | The Hobbit                                                                  |                0.9  |\n",
       "|                 8 | The Hitchhiker's Guide to the Galaxy (Hitchhiker's Guide to the Galaxy, #1) |                0.9  |\n",
       "|             24562 | Blood Promise (Vampire Academy, #4)                                         |                0.89 |\n",
       "|               602 | Neverwhere                                                                  |                0.89 |\n",
       "|              4562 | Dead to the World (Sookie Stackhouse, #4)                                   |                0.89 |\n",
       "|             26772 | Spirit Bound (Vampire Academy, #5)                                          |                0.89 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp_df = None\n",
    "indices = testset.get_user_record()\n",
    "user_ids = testset[indices[0]][0].repeat(book_titles_df.shape[0])\n",
    "item_ids = torch.LongTensor(book_titles_df.index.values)\n",
    "\n",
    "with torch.no_grad():\n",
    "    user_ids, item_ids = user_ids.to(device), item_ids.to(device)\n",
    "    predictions = model(user_ids, item_ids)\n",
    "\n",
    "    # tmp_df = pd.DataFrame(index=item_ids.numpy(), columns=['book_id', 'title', 'predicted_ratings'])\n",
    "    tmp_df = book_titles_df.copy()\n",
    "    tmp_df['predicted_ratings'] = predictions.cpu().round(decimals=2) * max_range\n",
    "    tmp_df.sort_values(by=['predicted_ratings'], ascending=False, inplace=True)\n",
    "    tmp_df = tmp_df.loc[tmp_df['title'].notna()]\n",
    "    display(Markdown(tmp_df[['title', 'predicted_ratings']].head(20).to_markdown()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops_projs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6277b8e4cbea501f918295b3c89da8b864a762da66687248877e66d072dbe1c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
